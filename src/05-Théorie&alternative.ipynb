{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> | - Questions théoriques :</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relire le cours sur Elastic Search à l’aide de nos nouvelles connaissance et répondre aux questions:\n",
    "1) Qu’est ce que le sharding, comment pourrait-on imaginer un sharding sur cet index?\n",
    "2) Quels ingestion pipelines seraient pertinents pour notre sujet.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponses :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) Le sharding est un concept clé dans Elasticsearch qui consiste à diviser un index en plusieurs fragments appelés shards.   \n",
    "    Chaque shard est une unité autonome qui contient une partie des données de l'index.   \n",
    "    Le sharding permet de distribuer les données sur plusieurs nœuds d'un cluster Elasticsearch, ce qui permet d'obtenir une meilleure répartition de la charge   \n",
    "    et d'améliorer les performances de recherche et de récupération des données."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Dans le cas de notre index, nous pouvons imaginer un sharding basé sur un critère tel que l'identifiant unique de chaque document.  \n",
    "    Par exemple, nous pouvons choisir de sharder l'index en fonction d'une plage d'identifiants, de sorte que les documents ayant   \n",
    "    des identifiants similaires soient regroupés dans le même shard. Cela permettrait de répartir la charge de manière équilibrée et de faciliter les opérations de recherche et d'agrégation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2) En ce qui concerne les pipelines d'ingestion, plusieurs options pourraient être pertinentes pour notre sujet. Voici quelques exemples :\n",
    "\n",
    "        Le pipeline de normalisation : Ce pipeline pourrait inclure des étapes telles que la suppression des caractères spéciaux, la normalisation des mots en minuscules, la suppression des stopwords, etc. Cela permettrait de standardiser le texte avant l'indexation, ce qui faciliterait les opérations de recherche.\n",
    "\n",
    "        Le pipeline de détection des émotions : Ce pipeline pourrait utiliser des techniques de traitement du langage naturel pour détecter les émotions présentes dans le texte, par exemple en utilisant des modèles de classification pré-entrainés ou des lexiques émotionnels. Cela permettrait d'extraire automatiquement les informations sur les émotions des textes lors de l'indexation.\n",
    "\n",
    "        Le pipeline d'extraction des entités : Ce pipeline pourrait utiliser des techniques de reconnaissance d'entités nommées pour extraire des informations telles que les noms de personnes, les lieux, les organisations, etc. Cela permettrait d'enrichir les données avec des métadonnées supplémentaires, facilitant ainsi les requêtes spécifiques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> || - Alternatives :</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
