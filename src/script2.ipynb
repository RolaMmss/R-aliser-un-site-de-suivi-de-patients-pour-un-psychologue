{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import texthero as hero\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from texthero import preprocessing\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données\n",
    "data= pd.read_csv(\"../data/Emotion_final.csv\")                                                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Emotion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition des textes par émotions\n",
    "emotion_counts = data['Emotion'].value_counts()\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=emotion_counts.index, y=emotion_counts.values)\n",
    "plt.xlabel('Emotions')\n",
    "plt.ylabel('Nombre de textes')\n",
    "plt.title('Répartition des textes par émotions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des données\n",
    "custom_pipeline = [\n",
    "    preprocessing.fillna,\n",
    "    preprocessing.lowercase,\n",
    "    preprocessing.remove_digits,\n",
    "    preprocessing.remove_punctuation,\n",
    "    preprocessing.remove_diacritics,\n",
    "    preprocessing.remove_whitespace,\n",
    "    preprocessing.remove_stopwords\n",
    "]\n",
    "\n",
    "data['clean_text'] = hero.clean(data['Text'], pipeline=custom_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des mots les plus courants pour chaque sentiment\n",
    "common_words_per_emotion = {}\n",
    "for emotion in data['Emotion'].unique():\n",
    "    mask = data['Emotion'] == emotion\n",
    "    text = data[mask]['clean_text']\n",
    "    words = ' '.join(text).split()\n",
    "    word_freq = FreqDist(words)\n",
    "    top_words = [word for word, freq in word_freq.most_common(30) if word not in stopwords.words('english')]\n",
    "    common_words_per_emotion[emotion] = top_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des 30 mots les plus courants pour chaque sentiment\n",
    "for emotion, words in common_words_per_emotion.items():\n",
    "    print(f\"Emotion: {emotion}\")\n",
    "    print(words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Création d'une matrice de proximité\n",
    "# emotions = list(common_words_per_emotion.keys())\n",
    "# distance_matrix = pd.DataFrame(index=emotions, columns=emotions)\n",
    "\n",
    "# for i, emotion1 in enumerate(emotions):\n",
    "#     for j, emotion2 in enumerate(emotions):\n",
    "#         if i == j:\n",
    "#             distance_matrix.loc[emotion1, emotion2] = 1.0\n",
    "#         else:\n",
    "#             common_words1 = common_words_per_emotion[emotion1]\n",
    "#             common_words2 = common_words_per_emotion[emotion2]\n",
    "#             vectorizer = CountVectorizer(vocabulary=set(common_words1 + common_words2))\n",
    "#             vectors = vectorizer.fit_transform([common_words1, common_words2])\n",
    "#             similarity = cosine_similarity(vectors)[0][1]\n",
    "#             distance_matrix.loc[emotion1, emotion2] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
